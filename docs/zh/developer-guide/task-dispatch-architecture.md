---
sidebar_position: 2
---

# ä»»åŠ¡æäº¤ä¸åˆ†å‘é“¾è·¯è®¾è®¡

æœ¬æ–‡æ¡£è¯¦ç»†æè¿° Wegent å¹³å°ä¸­ä»ä»»åŠ¡æäº¤åˆ°æ‰§è¡Œå®Œæˆçš„å®Œæ•´é“¾è·¯ï¼Œä»¥ `dispatcher.py` ä¸ºæ ¸å¿ƒï¼Œæ¶µç›–æ­£å¸¸æµç¨‹ï¼ˆhappy pathï¼‰çš„å…¨æµç¨‹è®¾è®¡ã€‚

---

## ğŸ“‹ ç›®å½•

- [æ•´ä½“æ¶æ„æ¦‚è§ˆ](#æ•´ä½“æ¶æ„æ¦‚è§ˆ)
- [æäº¤æ¥æºå±‚](#æäº¤æ¥æºå±‚)
- [è°ƒåº¦åˆ†å‘å±‚](#è°ƒåº¦åˆ†å‘å±‚)
- [æ‰§è¡Œå™¨å±‚](#æ‰§è¡Œå™¨å±‚)
- [æ•°æ®åè®®ä¸è½¬æ¢](#æ•°æ®åè®®ä¸è½¬æ¢)

---

## æ•´ä½“æ¶æ„æ¦‚è§ˆ

### æ¶æ„å…¨æ™¯å›¾

```mermaid
graph TB
    subgraph "æäº¤æ¥æºå±‚"
        Web["ğŸŒ ç½‘é¡µç«¯<br/>Next.js Frontend"]
        IM["ğŸ’¬ IM æ¸ é“<br/>DingTalk/Telegram"]
        Scheduled["â° å®šæ—¶ä»»åŠ¡<br/>Subscription/Scheduled"]
    end

    subgraph "è°ƒåº¦åˆ†å‘å±‚"
        Dispatcher["âš¡ ExecutionDispatcher<br/>backend/app/services/execution/dispatcher.py"]
        Router["ğŸ”€ ExecutionRouter<br/>backend/app/services/execution/router.py"]
        Emitter["ğŸ“¤ ResultEmitter<br/>WebSocket/SSE/Composite"]
    end

    subgraph "æ‰§è¡Œå™¨å±‚"
        ChatShell["ğŸ’¬ Chat Shell<br/>SSE Mode"]
        ClaudeCode["ğŸ§  Claude Code<br/>HTTP+Callback"]
        Agno["ğŸ’» Agno<br/>HTTP+Callback"]
        AIDevice["ğŸ“± AI Device<br/>WebSocket Mode"]
    end

    subgraph "æ•°æ®åè®®"
        ExecutionReq["ExecutionRequest<br/>å†…éƒ¨ç»Ÿä¸€è¯·æ±‚åè®®"]
        ExecutionEvent["ExecutionEvent<br/>å†…éƒ¨ç»Ÿä¸€äº‹ä»¶åè®®"]
        ResponseAPI["Responses API<br/>OpenAI æ ‡å‡†åè®®"]
    end

    %% æäº¤æ¥æºåˆ°è°ƒåº¦å±‚
    Web -->|HTTP API| Dispatcher
    IM -->|Channel Handler| Dispatcher
    Scheduled -->|Subscription Executor| Dispatcher

    %% è°ƒåº¦å±‚å†…éƒ¨
    Dispatcher --> Router
    Dispatcher --> Emitter

    %% è°ƒåº¦å±‚åˆ°æ‰§è¡Œå™¨
    Dispatcher -->|SSE| ChatShell
    Dispatcher -->|HTTP+Callback| ClaudeCode
    Dispatcher -->|HTTP+Callback| Agno
    Dispatcher -->|WebSocket| AIDevice

    %% åè®®è½¬æ¢
    ExecutionReq -.->|OpenAIRequestConverter| ResponseAPI
    ResponseAPI -.->|ResponsesAPIEventParser| ExecutionEvent

    %% æ ·å¼
    classDef submit fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef dispatch fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef executor fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    classDef protocol fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px

    class Web,IM,Scheduled submit
    class Dispatcher,Router,Emitter dispatch
    class ChatShell,ClaudeCode,Agno,AIDevice executor
    class ExecutionReq,ExecutionEvent,ResponseAPI protocol
```

### ä¸‰å±‚æ¶æ„è¯´æ˜

| å±‚æ¬¡ | èŒè´£ | æ ¸å¿ƒç»„ä»¶ |
|------|------|----------|
| **æäº¤æ¥æºå±‚** | æ¥æ”¶ç”¨æˆ·è¯·æ±‚ï¼Œæ„é€ ä»»åŠ¡æ•°æ® | ç½‘é¡µç«¯ã€IM æ¸ é“ã€å®šæ—¶ä»»åŠ¡ |
| **è°ƒåº¦åˆ†å‘å±‚** | è·¯ç”±å†³ç­–ã€åè®®è½¬æ¢ã€äº‹ä»¶åˆ†å‘ | `ExecutionDispatcher`ã€`ExecutionRouter`ã€`ResultEmitter` |
| **æ‰§è¡Œå™¨å±‚** | å®é™…æ‰§è¡Œ AI ä»»åŠ¡ | Chat Shellã€Claude Codeã€Agnoã€AI Device |

---

## æäº¤æ¥æºå±‚

### 1. ç½‘é¡µï¼ˆWebï¼‰æäº¤

#### å…¥å£ä»£ç ä½ç½®
- **API ç«¯ç‚¹**: `backend/app/api/endpoints/adapter/chat.py`
- **ä»»åŠ¡åˆ›å»º**: `backend/app/api/endpoints/adapter/tasks.py`
- **æ ¸å¿ƒå¤„ç†**: `backend/app/services/chat/trigger/unified.py::build_execution_request()`

#### è°ƒç”¨é“¾è·¯

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant Frontend as ğŸŒ å‰ç«¯
    participant ChatAPI as ğŸ’¬ Chat API
    participant TaskService as ğŸ“ Task Service
    participant Dispatcher as âš¡ Dispatcher

    User->>Frontend: è¾“å…¥æ¶ˆæ¯å¹¶å‘é€
    Frontend->>ChatAPI: POST /chat (StreamChatRequest)
    ChatAPI->>TaskService: åˆ›å»º/è·å– Task
    ChatAPI->>TaskService: åˆ›å»º Subtask (ç”¨æˆ·æ¶ˆæ¯)
    ChatAPI->>TaskService: åˆ›å»º Subtask (AIå ä½)
    ChatAPI->>Dispatcher: build_execution_request() + dispatch()
```

#### å…³é”®ä»£ç è·¯å¾„

**1. API å…¥å£** (`backend/app/api/endpoints/adapter/chat.py`):
```python
class StreamChatRequest(BaseModel):
    message: str
    team_id: int
    task_id: Optional[int] = None
    model_id: Optional[str] = None
    # ... å…¶ä»–å­—æ®µ
```

**2. æ„é€  ExecutionRequest** (`backend/app/services/chat/trigger/unified.py`):
```python
async def build_execution_request(
    task: TaskResource,
    assistant_subtask: Subtask,
    team: Kind,
    user: User,
    message: str,
    # ...
) -> ExecutionRequest:
    # æ„å»ºç»Ÿä¸€çš„ ExecutionRequest
    request = ExecutionRequest(
        task_id=task.id,
        subtask_id=assistant_subtask.id,
        user=user_dict,
        bot=bot_configs,
        model_config=model_config,
        prompt=message,
        # ...
    )
    return request
```

**3. æäº¤åˆ° Dispatcher**:
```python
from app.services.execution import execution_dispatcher

await execution_dispatcher.dispatch(
    request=execution_request,
    device_id=device_id,  # å¯é€‰ï¼ŒæŒ‡å®šæœ¬åœ°è®¾å¤‡
    emitter=emitter,  # å¯é€‰ï¼Œè‡ªå®šä¹‰ emitter
)
```

---

### 2. IMï¼ˆå³æ—¶é€šè®¯ï¼‰æäº¤

#### å…¥å£ä»£ç ä½ç½®
- **é’‰é’‰å¤„ç†å™¨**: `backend/app/services/channels/dingtalk/handler.py::DingTalkChannelHandler`
- **Telegram å¤„ç†å™¨**: `backend/app/services/channels/telegram/handler.py`
- **æŠ½è±¡åŸºç±»**: `backend/app/services/channels/handler.py::BaseChannelHandler`

#### è°ƒç”¨é“¾è·¯

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant IM as ğŸ’¬ IM å¹³å°
    participant Handler as ğŸ“± Channel Handler
    participant Dispatcher as âš¡ Dispatcher

    User->>IM: å‘é€æ¶ˆæ¯ @æœºå™¨äºº
    IM->>Handler: Webhook/Stream æ¨é€
    Handler->>Handler: parse_message() è§£ææ¶ˆæ¯
    Handler->>Handler: resolve_user() è§£æç”¨æˆ·
    Handler->>Handler: åˆ›å»º Task/Subtask
    Handler->>Dispatcher: dispatch() æäº¤ä»»åŠ¡
```

#### å…³é”®ä»£ç è·¯å¾„

**1. æ¶ˆæ¯è§£æ** (`backend/app/services/channels/handler.py`):
```python
@dataclass
class MessageContext:
    content: str           # æ¶ˆæ¯æ–‡æœ¬
    sender_id: str         # å‘é€è€… ID
    sender_name: str       # å‘é€è€…åç§°
    conversation_id: str   # ä¼šè¯ ID
    conversation_type: str # "private" æˆ– "group"
    is_mention: bool       # æ˜¯å¦è¢« @
    raw_message: Any       # åŸå§‹æ¶ˆæ¯å¯¹è±¡
```

**2. å¤„ç†å™¨å®ç°** (`backend/app/services/channels/dingtalk/handler.py`):
```python
class DingTalkChannelHandler(BaseChannelHandler):
    def parse_message(self, raw_data: Any) -> MessageContext:
        # è§£æé’‰é’‰æ¶ˆæ¯æ ¼å¼
        message: ChatbotMessage = raw_data
        content = message.text.content.strip()
        # ...
        return MessageContext(...)

    async def resolve_user(self, db: Session, context: MessageContext) -> Optional[User]:
        # å°†é’‰é’‰ç”¨æˆ·æ˜ å°„åˆ° Wegent ç”¨æˆ·
        resolver = DingTalkUserResolver(...)
        return await resolver.resolve_user(...)
```

**3. ä»»åŠ¡æäº¤**:
```python
# Channel handler å†…éƒ¨è°ƒç”¨ dispatcher
from app.services.execution import execution_dispatcher

await execution_dispatcher.dispatch(
    request=execution_request,
    device_id=device_id,  # å¯èƒ½æ ¹æ®ç”¨æˆ·é€‰æ‹©
)
```

---

### 3. å®šæ—¶ä»»åŠ¡ï¼ˆSubscription/Scheduledï¼‰æäº¤

#### å…¥å£ä»£ç ä½ç½®
- **ç»Ÿä¸€æ‰§è¡Œå™¨**: `backend/app/services/subscription/unified_executor.py`
- **æ‰§è¡Œæ•°æ®**: `backend/app/services/subscription/unified_executor.py::SubscriptionExecutionData`

#### è°ƒç”¨é“¾è·¯

```mermaid
sequenceDiagram
    participant Scheduler as â° APScheduler
    participant Trigger as ğŸ”” Trigger
    participant Unified as ğŸ“‹ Unified Executor
    participant Dispatcher as âš¡ Dispatcher

    Scheduler->>Trigger: å®šæ—¶è§¦å‘
    Trigger->>Unified: execute_subscription_unified()
    Unified->>Unified: build_execution_request()
    Unified->>Dispatcher: dispatch() æäº¤ä»»åŠ¡
```

#### å…³é”®ä»£ç è·¯å¾„

**1. æ‰§è¡Œæ•°æ®å®¹å™¨** (`backend/app/services/subscription/unified_executor.py`):
```python
@dataclass
class SubscriptionExecutionData:
    subscription_id: int
    execution_id: int
    task_id: int
    subtask_id: int
    prompt: str
    model_override_name: Optional[str]
    # ...
```

**2. ç»Ÿä¸€æ‰§è¡Œå…¥å£**:
```python
async def execute_subscription_unified(
    db: Session,
    task: TaskResource,
    assistant_subtask: Subtask,
    team: Kind,
    user: User,
    execution_data: SubscriptionExecutionData,
) -> None:
    # æ„å»º ExecutionRequest
    request = await build_execution_request(
        task=task,
        assistant_subtask=assistant_subtask,
        team=team,
        user=user,
        message=execution_data.prompt,
        is_subscription=True,  # æ ‡è®°ä¸ºè®¢é˜…ä»»åŠ¡
        # ...
    )

    # è·¯ç”±å†³ç­–
    router = ExecutionRouter()
    target = router.route(request, device_id=None)

    # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹å¼
    if target.mode == CommunicationMode.SSE:
        await _execute_sse_sync(request, execution_data)
    else:
        await _execute_http_callback(request, execution_data)
```

---

## è°ƒåº¦åˆ†å‘å±‚

### ExecutionDispatcher æ ¸å¿ƒè®¾è®¡

**æ–‡ä»¶ä½ç½®**: `backend/app/services/execution/dispatcher.py`

#### æ ¸å¿ƒèŒè´£

1. **ç»Ÿä¸€å…¥å£**: æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œçš„å”¯ä¸€å…¥å£
2. **è·¯ç”±å†³ç­–**: é€šè¿‡ `ExecutionRouter` ç¡®å®šæ‰§è¡Œç›®æ ‡
3. **åè®®è½¬æ¢**: å†…éƒ¨ `ExecutionRequest` â†” OpenAI Responses API
4. **äº‹ä»¶åˆ†å‘**: é€šè¿‡ `ResultEmitter` å‘å‰ç«¯æ¨é€äº‹ä»¶

#### ä¸»å…¥å£æ–¹æ³•

```python
class ExecutionDispatcher:
    async def dispatch(
        self,
        request: ExecutionRequest,
        device_id: Optional[str] = None,
        emitter: Optional[ResultEmitter] = None,
    ) -> None:
        """ç»Ÿä¸€ä»»åŠ¡åˆ†å‘å…¥å£ã€‚

        Args:
            request: ç»Ÿä¸€çš„æ‰§è¡Œè¯·æ±‚
            device_id: å¯é€‰çš„è®¾å¤‡ IDï¼ˆä½¿ç”¨ WebSocket æ¨¡å¼ï¼‰
            emitter: å¯é€‰çš„è‡ªå®šä¹‰äº‹ä»¶å‘å°„å™¨
        """
        # 1. è·¯ç”±å†³ç­–
        target = self.router.route(request, device_id)

        # 2. åˆ›å»ºé»˜è®¤ emitterï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if emitter is None:
            emitter = WebSocketResultEmitter(...)

        # 3. åŒ…è£…çŠ¶æ€æ›´æ–° emitter
        wrapped_emitter = StatusUpdatingEmitter(wrapped=emitter, ...)

        # 4. æ›´æ–°å­ä»»åŠ¡çŠ¶æ€ä¸º RUNNING
        await self._update_subtask_to_running(request.subtask_id)

        # 5. æ ¹æ®é€šä¿¡æ¨¡å¼åˆ†å‘
        if target.mode == CommunicationMode.SSE:
            await self._dispatch_sse(request, target, wrapped_emitter)
        elif target.mode == CommunicationMode.WEBSOCKET:
            await self._dispatch_websocket(request, target, wrapped_emitter)
        else:
            await self._dispatch_http_callback(request, target, wrapped_emitter)
```

### ExecutionRouter è·¯ç”±è§„åˆ™

**æ–‡ä»¶ä½ç½®**: `backend/app/services/execution/router.py`

#### é€šä¿¡æ¨¡å¼

```python
class CommunicationMode(str, Enum):
    SSE = "sse"              # Server-Sent Eventsï¼Œé•¿è¿æ¥æµå¼
    WEBSOCKET = "websocket"  # WebSocketï¼Œæœ¬åœ°è®¾å¤‡
    HTTP_CALLBACK = "http_callback"  # HTTP + å›è°ƒï¼Œå¼‚æ­¥
```

#### è·¯ç”±é…ç½®

```python
EXECUTION_SERVICES = {
    "Chat": {
        "mode": "sse",
        "url": settings.CHAT_SHELL_URL,  # http://127.0.0.1:8100
    },
    "ClaudeCode": {
        "mode": "http_callback",
        "url": settings.EXECUTOR_MANAGER_URL + "/executor-manager",
    },
    "Agno": {
        "mode": "http_callback",
        "url": settings.EXECUTOR_MANAGER_URL + "/executor-manager",
    },
    "Dify": {
        "mode": "http_callback",
        "url": settings.EXECUTOR_MANAGER_URL + "/executor-manager",
    },
}
```

#### è·¯ç”±ä¼˜å…ˆçº§

1. **Priority 1**: å¦‚æœæŒ‡å®šäº† `device_id`ï¼Œä½¿ç”¨ **WebSocket æ¨¡å¼**
2. **Priority 2**: æ ¹æ® `shell_type` æŸ¥æ‰¾é…ç½®ï¼ˆChat/ClaudeCode/Agno/Difyï¼‰
3. **Priority 3**: é»˜è®¤ä½¿ç”¨ **HTTP+Callback æ¨¡å¼**

---

## æ‰§è¡Œå™¨å±‚

### 1. Chat Shellï¼ˆSSE æ¨¡å¼ï¼‰

**å…¥å£**: `chat_shell/chat_shell/api/v1/response.py`

#### ç‰¹ç‚¹
- **é€šä¿¡æ¨¡å¼**: SSEï¼ˆServer-Sent Eventsï¼‰
- **åè®®**: OpenAI Responses API
- **é€‚ç”¨åœºæ™¯**: ç›´æ¥å¯¹è¯ï¼Œæ— éœ€ä»£ç æ‰§è¡Œ

#### è°ƒç”¨æµç¨‹
```python
# dispatcher.py::_dispatch_sse()
client = AsyncOpenAI(
    base_url=f"{target.url}/v1",
    api_key="dummy",
)

# è½¬æ¢è¯·æ±‚æ ¼å¼
openai_request = OpenAIRequestConverter.from_execution_request(request)

# å‘é€æµå¼è¯·æ±‚
stream = await client.responses.create(
    model=openai_request.get("model"),
    input=openai_request.get("input"),
    instructions=openai_request.get("instructions"),
    tools=tools if tools else None,
    stream=True,
    extra_body={...},
)

# å¤„ç†æµå¼äº‹ä»¶
async for event in stream:
    parsed_event = self.event_parser.parse(...)
    if parsed_event:
        await emitter.emit(parsed_event)
```

---

### 2. Claude Codeï¼ˆHTTP+Callback æ¨¡å¼ï¼‰

**å…¥å£**: `executor/agents/claude_code/claude_code_agent.py::ClaudeCodeAgent`

#### ç‰¹ç‚¹
- **é€šä¿¡æ¨¡å¼**: HTTP + Callback
- **æ‰§è¡Œç¯å¢ƒ**: Docker å®¹å™¨
- **é€‚ç”¨åœºæ™¯**: ä»£ç ä»»åŠ¡ï¼Œæ”¯æŒ Gitã€MCPã€Skills

#### è°ƒç”¨æµç¨‹
```python
# dispatcher.py::_dispatch_http_callback()
response = await client.responses.create(
    model=openai_request.get("model"),
    input=openai_request.get("input"),
    instructions=openai_request.get("instructions"),
    tools=tools if tools else None,
    stream=False,  # éæµå¼
    extra_body={
        "background": True,  # åå°æ‰§è¡Œ
        "metadata": {...},
    },
)

# åç»­äº‹ä»¶é€šè¿‡ /internal/callback æ¥æ”¶
```

---

### 3. Agnoï¼ˆHTTP+Callback æ¨¡å¼ï¼‰

**å…¥å£**: `executor/agents/agno/agno_agent.py::AgnoAgent`

#### ç‰¹ç‚¹
- **é€šä¿¡æ¨¡å¼**: HTTP + Callback
- **æ‰§è¡Œç¯å¢ƒ**: Docker å®¹å™¨
- **é€‚ç”¨åœºæ™¯**: å¤šæ™ºèƒ½ä½“åä½œï¼ˆcoordinate/collaborate/route æ¨¡å¼ï¼‰

---

### 4. AI Deviceï¼ˆWebSocket æ¨¡å¼ï¼‰

**å…¥å£**: æœ¬åœ°è®¾å¤‡é€šè¿‡ WebSocket æ¥æ”¶ä»»åŠ¡

#### ç‰¹ç‚¹
- **é€šä¿¡æ¨¡å¼**: WebSocketï¼ˆSocket.IOï¼‰
- **å‘½åç©ºé—´**: `/local-executor`
- **äº‹ä»¶**: `task:execute`
- **é€‚ç”¨åœºæ™¯**: æœ¬åœ°å¼€å‘ç¯å¢ƒï¼Œä½¿ç”¨ç”¨æˆ·æœ¬åœ°èµ„æº

#### è°ƒç”¨æµç¨‹
```python
# dispatcher.py::_dispatch_websocket()
await sio.emit(
    "task:execute",
    request.to_dict(),
    room=f"device:{user_id}:{device_id}",
    namespace="/local-executor",
)

# è®¾å¤‡æ‰§è¡Œåé€šè¿‡ on_task_progress/on_task_complete å›è°ƒ
```

---

## æ•°æ®åè®®ä¸è½¬æ¢

### åè®®æ¦‚è§ˆ

```mermaid
graph LR
    subgraph "å†…éƒ¨åè®®"
        ER["ExecutionRequest<br/>ç»Ÿä¸€è¯·æ±‚æ ¼å¼"]
        EE["ExecutionEvent<br/>ç»Ÿä¸€äº‹ä»¶æ ¼å¼"]
    end

    subgraph "å¤–éƒ¨åè®®"
        OA["OpenAI Responses API<br/>æ ‡å‡† OpenAI æ ¼å¼"]
    end

    subgraph "å‰ç«¯åè®®"
        WS["WebSocket Events<br/>chat:start/chunk/done"]
    end

    ER -->|OpenAIRequestConverter| OA
    OA -->|ResponsesAPIEventParser| EE
    EE -->|WebSocketResultEmitter| WS

    classDef internal fill:#e3f2fd,stroke:#1976d2
    classDef external fill:#e8f5e9,stroke:#388e3c
    classDef frontend fill:#fff3e0,stroke:#f57c00

    class ER,EE internal
    class OA external
    class WS frontend
```

---

### 1. ExecutionRequestï¼ˆå†…éƒ¨è¯·æ±‚åè®®ï¼‰

**å®šä¹‰ä½ç½®**: `shared/models/execution.py::ExecutionRequest`

#### æ ¸å¿ƒå­—æ®µ

```python
@dataclass
class ExecutionRequest:
    # === ä»»åŠ¡æ ‡è¯† ===
    task_id: int = 0
    subtask_id: int = 0
    team_id: int = 0

    # === ç”¨æˆ·ä¿¡æ¯ ===
    user: dict = field(default_factory=dict)
    user_id: int = 0

    # === Bot é…ç½® ===
    bot: list = field(default_factory=list)  # åŒ…å« shell_type
    bot_name: str = ""

    # === æ¨¡å‹é…ç½® ===
    model_config: dict = field(default_factory=dict)

    # === æç¤ºè¯ ===
    system_prompt: str = ""
    prompt: str = ""  # ç”¨æˆ·æ¶ˆæ¯

    # === åŠŸèƒ½å¼€å…³ ===
    enable_tools: bool = True
    enable_web_search: bool = False

    # === Skill é…ç½® ===
    skill_names: list = field(default_factory=list)
    mcp_servers: list = field(default_factory=list)

    # === å·¥ä½œç©ºé—´ ===
    workspace: dict = field(default_factory=dict)

    # === Git é…ç½® ===
    git_domain: Optional[str] = None
    git_repo: Optional[str] = None
    branch_name: Optional[str] = None

    # === ä¼šè¯é…ç½® ===
    history: list = field(default_factory=list)
    is_group_chat: bool = False

    # === è®¢é˜…ä»»åŠ¡æ ‡è®° ===
    is_subscription: bool = False
```

---

### 2. ExecutionEventï¼ˆå†…éƒ¨äº‹ä»¶åè®®ï¼‰

**å®šä¹‰ä½ç½®**: `shared/models/execution.py::ExecutionEvent`

#### äº‹ä»¶ç±»å‹

```python
class EventType(str, Enum):
    START = "start"           # å¼€å§‹ç”Ÿæˆ
    CHUNK = "chunk"           # å†…å®¹ç‰‡æ®µ
    THINKING = "thinking"     # æ€è€ƒè¿‡ç¨‹
    TOOL_START = "tool_start" # å·¥å…·è°ƒç”¨å¼€å§‹
    TOOL_RESULT = "tool_result" # å·¥å…·è°ƒç”¨ç»“æœ
    DONE = "done"             # å®Œæˆ
    ERROR = "error"           # é”™è¯¯
    CANCELLED = "cancelled"   # å–æ¶ˆ
```

#### æ ¸å¿ƒå­—æ®µ

```python
@dataclass
class ExecutionEvent:
    type: str              # EventType å€¼
    task_id: int
    subtask_id: int
    content: str = ""      # æ–‡æœ¬å†…å®¹
    offset: int = 0        # æµå¼åç§»é‡
    result: Optional[dict] = None  # ç»“æœæ•°æ®
    error: Optional[str] = None
    tool_name: Optional[str] = None
    tool_use_id: Optional[str] = None
    tool_input: Optional[dict] = None
    tool_output: Optional[Any] = None
```

---

### 3. Responses APIï¼ˆOpenAI æ ‡å‡†åè®®ï¼‰

**å®šä¹‰ä½ç½®**: `shared/models/responses_api.py`

#### äº‹ä»¶ç±»å‹

```python
class ResponsesAPIStreamEvents(Enum):
    # å“åº”ç”Ÿå‘½å‘¨æœŸ
    RESPONSE_CREATED = "response.created"
    RESPONSE_IN_PROGRESS = "response.in_progress"
    RESPONSE_COMPLETED = "response.completed"
    RESPONSE_INCOMPLETE = "response.incomplete"

    # å†…å®¹è¾“å‡º
    OUTPUT_ITEM_ADDED = "response.output_item.added"
    OUTPUT_ITEM_DONE = "response.output_item.done"
    CONTENT_PART_ADDED = "response.content_part.added"
    CONTENT_PART_DONE = "response.content_part.done"
    OUTPUT_TEXT_DELTA = "response.output_text.delta"
    OUTPUT_TEXT_DONE = "response.output_text.done"

    # å‡½æ•°è°ƒç”¨
    FUNCTION_CALL_ARGUMENTS_DELTA = "response.function_call_arguments.delta"
    FUNCTION_CALL_ARGUMENTS_DONE = "response.function_call_arguments.done"

    # æ¨ç†
    RESPONSE_PART_ADDED = "response.reasoning_summary_part.added"

    # é”™è¯¯
    ERROR = "error"
```

---

### 4. åè®®è½¬æ¢æµç¨‹

#### å®Œæ•´æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant Source as æäº¤æ¥æº
    participant Dispatcher as ExecutionDispatcher
    participant Converter as OpenAIRequestConverter
    participant Executor as æ‰§è¡Œå™¨
    participant Parser as ResponsesAPIEventParser
    participant Emitter as ResultEmitter
    participant Frontend as å‰ç«¯

    %% è¯·æ±‚é˜¶æ®µï¼šå†…éƒ¨ â†’ OpenAI
    Source->>Dispatcher: ExecutionRequest
    Dispatcher->>Converter: from_execution_request()
    Note over Converter: è½¬æ¢å­—æ®µï¼š<br/>- prompt â†’ input<br/>- system_prompt â†’ instructions<br/>- mcp_servers â†’ tools<br/>- å…¶ä»–å­—æ®µ â†’ metadata
    Converter->>Dispatcher: OpenAI æ ¼å¼è¯·æ±‚

    %% æ‰§è¡Œé˜¶æ®µ
    Dispatcher->>Executor: å‘é€ OpenAI è¯·æ±‚
    Executor->>Dispatcher: è¿”å›æµå¼äº‹ä»¶

    %% å“åº”é˜¶æ®µï¼šOpenAI â†’ å†…éƒ¨
    Dispatcher->>Parser: parse(event_type, data)
    Note over Parser: äº‹ä»¶æ˜ å°„ï¼š<br/>- output_text.delta â†’ CHUNK<br/>- response.completed â†’ DONE<br/>- function_call_arguments.done â†’ TOOL_RESULT<br/>- reasoning_summary_part.added â†’ THINKING
    Parser->>Dispatcher: ExecutionEvent

    %% åˆ†å‘é˜¶æ®µ
    Dispatcher->>Emitter: emit(ExecutionEvent)
    Emitter->>Frontend: WebSocket äº‹ä»¶
```

#### è¯·æ±‚è½¬æ¢ï¼ˆExecutionRequest â†’ OpenAIï¼‰

**è½¬æ¢å™¨**: `shared/models/openai_converter.py::OpenAIRequestConverter`

| å†…éƒ¨å­—æ®µ | OpenAI å­—æ®µ | è¯´æ˜ |
|----------|-------------|------|
| `prompt` | `input` | ç”¨æˆ·è¾“å…¥ |
| `system_prompt` | `instructions` | ç³»ç»Ÿæç¤ºè¯ |
| `mcp_servers` | `tools` | MCP å·¥å…·åˆ—è¡¨ |
| `model_config.model_id` | `model` | æ¨¡å‹æ ‡è¯† |
| å…¶ä»–å­—æ®µ | `metadata` | è‡ªå®šä¹‰å…ƒæ•°æ® |
| `model_config` | `model_config` | æ¨¡å‹é…ç½®ï¼ˆextra_bodyï¼‰ |

```python
@staticmethod
def from_execution_request(request: ExecutionRequest) -> dict[str, Any]:
    openai_request = {
        "model": request.model_config.get("model_id", ""),
        "input": request.prompt,
        "stream": True,
    }

    if request.system_prompt:
        openai_request["instructions"] = request.system_prompt

    # MCP servers è½¬æ¢ä¸º tools
    tools = []
    if request.mcp_servers:
        for server in request.mcp_servers:
            tool = {
                "type": "mcp",
                "server_label": server.get("name", ""),
                "server_url": server.get("url", ""),
            }
            tools.append(tool)

    if tools:
        openai_request["tools"] = tools

    # å…¶ä»–å­—æ®µæ”¾å…¥ metadata
    openai_request["metadata"] = {
        "task_id": request.task_id,
        "subtask_id": request.subtask_id,
        "user": request.user,
        # ...
    }

    return openai_request
```

#### äº‹ä»¶è½¬æ¢ï¼ˆOpenAI â†’ ExecutionEventï¼‰

**è½¬æ¢å™¨**: `backend/app/services/execution/dispatcher.py::ResponsesAPIEventParser`

| OpenAI äº‹ä»¶ | å†…éƒ¨äº‹ä»¶ | è¯´æ˜ |
|-------------|----------|------|
| `response.output_text.delta` | `CHUNK` | æ–‡æœ¬ç‰‡æ®µ |
| `response.completed` | `DONE` | å®Œæˆ |
| `response.incomplete` | `CANCELLED` | å–æ¶ˆ/ä¸å®Œæ•´ |
| `response.output_item.added` (function_call) | `TOOL_START` | å·¥å…·è°ƒç”¨å¼€å§‹ |
| `response.function_call_arguments.done` | `TOOL_RESULT` | å·¥å…·è°ƒç”¨ç»“æœ |
| `response.reasoning_summary_part.added` | `THINKING` | æ€è€ƒè¿‡ç¨‹ |
| `error` | `ERROR` | é”™è¯¯ |

```python
@staticmethod
def parse(task_id, subtask_id, message_id, event_type, data) -> Optional[ExecutionEvent]:
    if event_type == ResponsesAPIStreamEvents.OUTPUT_TEXT_DELTA.value:
        return ExecutionEvent(
            type=EventType.CHUNK,
            task_id=task_id,
            subtask_id=subtask_id,
            content=data.get("delta", ""),
            offset=data.get("offset", 0),
        )

    elif event_type == ResponsesAPIStreamEvents.RESPONSE_COMPLETED.value:
        return ExecutionEvent(
            type=EventType.DONE,
            task_id=task_id,
            subtask_id=subtask_id,
            result={
                "value": extracted_text,
                "usage": response_data.get("usage"),
                "sources": response_data.get("sources"),
            },
        )

    elif event_type == ResponsesAPIStreamEvents.FUNCTION_CALL_ARGUMENTS_DONE.value:
        return ExecutionEvent(
            type=EventType.TOOL_RESULT,
            task_id=task_id,
            subtask_id=subtask_id,
            tool_use_id=data.get("call_id"),
            tool_output=data.get("output"),
        )

    # ... å…¶ä»–äº‹ä»¶ç±»å‹
```

---

## å®Œæ•´æµç¨‹æ—¶åºå›¾

```mermaid
sequenceDiagram
    autonumber
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant Frontend as ğŸŒ å‰ç«¯
    participant API as ğŸ“¡ API å±‚
    participant Dispatcher as âš¡ Dispatcher
    participant Router as ğŸ”€ Router
    participant Converter as ğŸ”„ åè®®è½¬æ¢
    participant Executor as ğŸš€ æ‰§è¡Œå™¨
    participant Emitter as ğŸ“¤ Emitter

    %% é˜¶æ®µ 1: ä»»åŠ¡æäº¤
    User->>Frontend: è¾“å…¥æ¶ˆæ¯
    Frontend->>API: POST /chat (StreamChatRequest)
    API->>API: åˆ›å»º Task + Subtask
    API->>Dispatcher: dispatch(ExecutionRequest)

    %% é˜¶æ®µ 2: è·¯ç”±å†³ç­–
    Dispatcher->>Router: route(request, device_id)
    Router->>Dispatcher: ExecutionTarget(mode, url)

    %% é˜¶æ®µ 3: åè®®è½¬æ¢ï¼ˆè¯·æ±‚ï¼‰
    Dispatcher->>Converter: from_execution_request()
    Note right of Converter: ExecutionRequest â†’ OpenAI

    %% é˜¶æ®µ 4: ä»»åŠ¡æ‰§è¡Œ
    alt SSE Mode (Chat Shell)
        Dispatcher->>Executor: POST /v1/responses (stream=True)
        Executor->>Dispatcher: æµå¼è¿”å› SSE äº‹ä»¶
    else HTTP+Callback (ClaudeCode/Agno)
        Dispatcher->>Executor: POST /v1/responses (background=True)
        Executor->>Dispatcher: ç«‹å³è¿”å› queued
        Note right of Executor: å¼‚æ­¥æ‰§è¡Œï¼Œå›è°ƒæ›´æ–°
    else WebSocket Mode (AI Device)
        Dispatcher->>Executor: emit task:execute
        Note right of Executor: è®¾å¤‡ä¸»åŠ¨è¿æ¥ï¼Œé•¿è¿æ¥
    end

    %% é˜¶æ®µ 5: åè®®è½¬æ¢ï¼ˆå“åº”ï¼‰
    Dispatcher->>Converter: parse(event_type, data)
    Note right of Converter: OpenAI â†’ ExecutionEvent

    %% é˜¶æ®µ 6: äº‹ä»¶åˆ†å‘
    Dispatcher->>Emitter: emit(ExecutionEvent)
    Emitter->>Frontend: WebSocket æ¨é€

    %% é˜¶æ®µ 7: å‰ç«¯å±•ç¤º
    Frontend->>User: å®æ—¶æ˜¾ç¤º AI å›å¤
```

---

## å…³é”®æ–‡ä»¶ç´¢å¼•

| ç»„ä»¶ | æ–‡ä»¶è·¯å¾„ | è¯´æ˜ |
|------|----------|------|
| **Dispatcher** | `backend/app/services/execution/dispatcher.py` | ç»Ÿä¸€è°ƒåº¦å…¥å£ |
| **Router** | `backend/app/services/execution/router.py` | è·¯ç”±å†³ç­– |
| **ExecutionRequest** | `shared/models/execution.py` | å†…éƒ¨è¯·æ±‚åè®® |
| **OpenAI è½¬æ¢å™¨** | `shared/models/openai_converter.py` | åè®®è½¬æ¢ |
| **Responses API** | `shared/models/responses_api.py` | OpenAI äº‹ä»¶å®šä¹‰ |
| **WebSocket Emitter** | `backend/app/services/execution/emitters/websocket.py` | å‰ç«¯äº‹ä»¶æ¨é€ |
| **Chat API** | `backend/app/api/endpoints/adapter/chat.py` | ç½‘é¡µç«¯å…¥å£ |
| **Task API** | `backend/app/api/endpoints/adapter/tasks.py` | ä»»åŠ¡ç®¡ç† API |
| **Channel Handler** | `backend/app/services/channels/handler.py` | IM æ¸ é“åŸºç±» |
| **Subscription Executor** | `backend/app/services/subscription/unified_executor.py` | å®šæ—¶ä»»åŠ¡æ‰§è¡Œ |

---

<p align="center">ç†è§£ä»»åŠ¡åˆ†å‘é“¾è·¯æ˜¯æŒæ¡ Wegent æ‰§è¡Œæœºåˆ¶çš„å…³é”®ï¼ğŸš€</p>
